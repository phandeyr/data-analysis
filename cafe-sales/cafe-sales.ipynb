{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10500284,"sourceType":"datasetVersion","datasetId":6501209}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro \nWe want to analyse cafe sales to provide valuable insights into customer behavior, product popularity and revenue patterns.","metadata":{}},{"cell_type":"markdown","source":"# Step 1. Read & Inspect Dataframe","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Read csv\ndf = pd.read_csv(\"/kaggle/input/cafe-sales-dirty-data-for-cleaning-training/dirty_cafe_sales.csv\")\n# Copy dataset for cleaning\ndf_clean = df.copy()\ndf_clean.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:01:23.832207Z","iopub.execute_input":"2025-02-16T13:01:23.832548Z","iopub.status.idle":"2025-02-16T13:01:23.863034Z","shell.execute_reply.started":"2025-02-16T13:01:23.832523Z","shell.execute_reply":"2025-02-16T13:01:23.862134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2. Perform data cleaning\n* Convert total spent, quantity and price per unit columns to numeric data type\n* Populate missing values\n* Convert transaction date to datetime data type\n* Add column transaction month","metadata":{}},{"cell_type":"code","source":"# Unique prices dict\nunique_prices = {\n    'Cookie': 1.0,\n    'Tea': 1.5,\n    'Coffee': 2.0,\n    'Salad': 5.0\n}\n\n# Non unique Prices dict\nnon_unique_prices = {\n    'Juice': 3.0,\n    'Cake': 3.0,\n    'Sandwich': 4.0,\n    'Smoothie': 4.0\n}\n\n# Combined prices dict\nprices = unique_prices | non_unique_prices\n\n# Convert to numeric\ndf_clean[['Total Spent', 'Quantity', 'Price Per Unit']] = df_clean[['Total Spent', 'Quantity', 'Price Per Unit']].apply(pd.to_numeric, errors='coerce', axis=1)\n\n# Populate Price Per Unit (1.Based on Item, 2.Total Spent / Quantity)\ndf_clean['Price Per Unit'] = df_clean.apply(lambda row: prices.get(row['Item']) if pd.isna(row['Price Per Unit']) else row['Price Per Unit'], axis=1)\ndf_clean['Price Per Unit'] = df_clean.apply(lambda row: row['Total Spent'] / row['Quantity'] if pd.isna(row['Price Per Unit']) else row['Price Per Unit'], axis=1)\n# Drop rows where Price Per Unit is NaN (6 rows)\ndf_clean.dropna(subset=['Price Per Unit'], inplace=True)\n# Drop rows where Total Spent & Quantity is NaN (20 rows)\ndf_clean.dropna(subset=['Total Spent', 'Quantity'], how='all', inplace=True)\n\n# Populate Total Spent (Quantity * Price Per Unit)\ndf_clean['Total Spent'] = df_clean.apply(lambda row: row['Quantity'] * row['Price Per Unit'] if pd.isna(row['Total Spent']) else row['Total Spent'], axis=1)\n\n# Populate Quantity (Total Spent / Price Per Unit)\ndf_clean['Quantity'] = df_clean.apply(lambda row: row['Total Spent'] * row['Price Per Unit'] if pd.isna(row['Quantity']) else row['Quantity'], axis=1)\n\n# Convert UNKNOWN & ERROR items to NaN (963 rows)\ndf_clean['Item'] = df_clean['Item'].replace({'UNKNOWN': np.nan, 'ERROR': np.nan})\ndf_clean[df_clean['Item'].isna()]\n# Populate Item (Based on unique prices) \ndf_clean['Item'] = df_clean.apply(lambda row: next((k for k, v in unique_prices.items() if v == row['Price Per Unit']), row['Item']), axis=1)\n\n# Convert to date \ndf_clean['Transaction Date'] = pd.to_datetime(df_clean['Transaction Date'], errors='coerce')\n# Drop rows where Transaction Date is NaN\ndf_clean.dropna(subset=['Transaction Date'], inplace=True)\n# Add new column 'Transaction Month'\ndf_clean['Transaction Month'] = pd.to_datetime(df_clean['Transaction Date']).dt.strftime('%B')\n\ndf_clean.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:01:23.864161Z","iopub.execute_input":"2025-02-16T13:01:23.864465Z","iopub.status.idle":"2025-02-16T13:01:25.501310Z","shell.execute_reply.started":"2025-02-16T13:01:23.864431Z","shell.execute_reply":"2025-02-16T13:01:25.500440Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3. Data Aggregation","metadata":{}},{"cell_type":"code","source":"# Quantity Sold Per Month\ndf_quantities_pivot = df_clean.pivot_table(index='Transaction Month', columns='Item', values='Quantity', aggfunc='sum')\ndf_quantities_pivot.reset_index(inplace=True)\ndf_quantities_pivot['Transaction Month No'] = pd.to_datetime(df_quantities_pivot['Transaction Month'], format='%B').dt.month\ndf_quantities_pivot.sort_values('Transaction Month No', inplace=True)\ndf_quantities_pivot.drop(columns='Transaction Month No', inplace=True)\n\n# Monthly Revenue\ndf_revenue_pivot = df_clean.pivot_table(index='Transaction Month', columns='Item', values='Total Spent', aggfunc='sum')\ndf_revenue_pivot.reset_index(inplace=True)\ndf_revenue_pivot['Transaction Month No'] = pd.to_datetime(df_quantities_pivot['Transaction Month'], format='%B').dt.month\ndf_revenue_pivot.sort_values('Transaction Month No', inplace=True)\ndf_revenue_pivot.drop(columns='Transaction Month No', inplace=True)\ndf_revenue_pivot['Monthly Revenue'] = df_revenue_pivot[list(prices.keys())].sum(axis=1)\n\n# Revenue by Item \nrevenue = df_clean.groupby('Item')['Total Spent'].agg(['sum']).sort_values(by='sum', ascending=False)\n\ndf_revenue_pivot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:01:25.502930Z","iopub.execute_input":"2025-02-16T13:01:25.503288Z","iopub.status.idle":"2025-02-16T13:01:25.550133Z","shell.execute_reply.started":"2025-02-16T13:01:25.503251Z","shell.execute_reply":"2025-02-16T13:01:25.549327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4. Create Plots\nThree subplots will be created to show the revenue by item, top 3 selling items and monthly revenue.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(3,1, figsize=(12,14))\n\n# Revenue by Item\nsns.set_theme(style='ticks')\nsns.barplot(data=revenue, x='sum', y=revenue.index, palette='dark:b', ax=ax[0])\nsns.despine()\nax[0].set_xlabel('')\nax[0].set_ylabel('')\nax[0].set_title('Revenue by Item')\nax[0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'£{int(x/1000)}K'))\n\n# Top 3 Selling Items\ntop_3 = df_clean.groupby('Item')['Quantity'].agg(['sum']).sort_values(by='sum', ascending=False)\ntop_3 = top_3.head(3).index.tolist()\ndf_top_3 = df_quantities_pivot.melt(id_vars='Transaction Month', value_vars=top_3, var_name='Item', value_name='Quantity')\nsns.barplot(data=df_top_3, x='Transaction Month', y='Quantity', hue='Item', ax=ax[1])\nax[1].set_title('Top 3 Selling Items')\nax[1].set_xlabel('')\nax[1].set_ylabel('')\nplt.setp(ax[1].get_xticklabels(), rotation=45, ha='right')\nax[1].legend(loc='upper right', ncol=3)\n\n# Monthly Revenue\nsns.lineplot(data=df_revenue_pivot, x='Transaction Month', y='Monthly Revenue', linewidth=3)\nax[2].set_title('Monthly Revenue')\nax[2].set_xlabel('')\nax[2].set_ylabel('')\nax[2].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'£{x/1000:.1f}K'))\nplt.setp(ax[2].get_xticklabels(), rotation=45, ha='right')\n\nfig.suptitle('Cafe Sales 2023 Analysis', fontsize=20)\nfig.tight_layout()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:01:25.551075Z","iopub.execute_input":"2025-02-16T13:01:25.551308Z","iopub.status.idle":"2025-02-16T13:01:26.499850Z","shell.execute_reply.started":"2025-02-16T13:01:25.551287Z","shell.execute_reply":"2025-02-16T13:01:26.498804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5. Analysis\n**Revenue by Item**\nWe can observe that salad generated the highest revenue, earning approximately £5k more than the second-highest item, while cookie generated the lowest revenue.\n\n**Top 3 Selling Items**\nMonth by month, salad is usually the most purchased item, with sales peaking in June as summer begins. Sales dip in September, likely due to the arrival of autumn, but overall, this pattern indicates that people are health conscious. Sandwiches and smoothies are also among the top selling items, further supporting the trend of health conscious consumer choices. This aligns with the fact that the highest revenue-generating items are salads, sandwiches and smoothies.\n\n**Monthly Revenue**\nThe monthly revenue consistently falls between £6k and £7k, with February being the lowest revenue month. After the festive season in December and the New Year, people tend to tighten their budgets, hence this could result in fewer visits to cafes in February. A promotion could be a good strategy to boost revenue during February, such as Valentine's-themed specials. October is the highest revenue month, suggesting that as the weather cools, people are more inclined to enjoy warm drinks. This is further supported by the fact that October's tea revenue is the highest at £522, and coffee revenue also peaks at £750.","metadata":{}}]}